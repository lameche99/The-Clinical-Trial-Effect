{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_csv_to_list(file_path):\n",
    "    \"\"\"\n",
    "    Read a CSV file and store its content as a list of strings.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of strings read from the CSV file.\n",
    "    \"\"\"\n",
    "    string_list = []\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', newline='') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            for row in csv_reader:\n",
    "                for item in row:\n",
    "                    string_list.append(item)\n",
    "\n",
    "            csv_file.close()\n",
    "\n",
    "        return string_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{AADI} No Data for 2015-01-01 to 2017-09-27.\n",
      "{AADI} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ABCL} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ABCL} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ABOS} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ABOS} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ABVC} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ABVC} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ACHL} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ACHL} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ACLX} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ACLX} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ACRV} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ACRV} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ACXP} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ACXP} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ADAG} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ADAG} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ADCT} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ADGI} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ADGI} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ADGI} No Data for 2023-03-23 to 2025-12-17.\n",
      "{ADIL} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ADTX} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ADTX} No Data for 2017-09-28 to 2020-06-24.\n",
      "{AERI} No Data for 2023-03-23 to 2025-12-17.\n",
      "{AGTC} No Data for 2023-03-23 to 2025-12-17.\n",
      "{AIM} No Data for 2015-01-01 to 2017-09-27.\n",
      "{AIMD} No Data for 2015-01-01 to 2017-09-27.\n",
      "{AIMD} No Data for 2017-09-28 to 2020-06-24.\n",
      "{AKRO} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ALBO} No Data for 2023-03-23 to 2025-12-17.\n",
      "{ALEC} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ALGS} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ALGS} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ALLK} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ALLK} No Data for 2023-03-23 to 2025-12-17.\n",
      "{ALLO} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ALLR} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ALLR} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ALNA} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ALNA} No Data for 2023-03-23 to 2025-12-17.\n",
      "{ALPMY} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ALPMY} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ALVO} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ALVO} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ALVR} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ALVR} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ALXO} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ALXO} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ALZN} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ALZN} No Data for 2017-09-28 to 2020-06-24.\n",
      "{AMAM} No Data for 2015-01-01 to 2017-09-27.\n",
      "{AMAM} No Data for 2017-09-28 to 2020-06-24.\n",
      "{AMRX} No Data for 2015-01-01 to 2017-09-27.\n",
      "{AMTI} No Data for 2015-01-01 to 2017-09-27.\n",
      "{AMYT} No Data for 2015-01-01 to 2017-09-27.\n",
      "{AMYT} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ANEB} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ANEB} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ANIX} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ANNX} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ANNX} No Data for 2017-09-28 to 2020-06-24.\n",
      "{ANVS} No Data for 2015-01-01 to 2017-09-27.\n",
      "{APLIF} No Data for 2015-01-01 to 2017-09-27.\n",
      "{APLIF} No Data for 2017-09-28 to 2020-06-24.\n",
      "{APLS} No Data for 2015-01-01 to 2017-09-27.\n",
      "{APLT} No Data for 2015-01-01 to 2017-09-27.\n",
      "{APM} No Data for 2015-01-01 to 2017-09-27.\n",
      "{APRE} No Data for 2015-01-01 to 2017-09-27.\n",
      "{APTX} No Data for 2015-01-01 to 2017-09-27.\n",
      "{AQST} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ARAV} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ARCT} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ARDS} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ARMP} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ARQT} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ARTL} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ARVN} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ASLN} No Data for 2015-01-01 to 2017-09-27.\n",
      "{ASRT} No Data for 2015-01-01 to 2017-09-27.\n"
     ]
    }
   ],
   "source": [
    "from polygon import RESTClient\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "# Function to check for API errors and handle them\n",
    "def get_data(client, ticker, start_date, end_date):\n",
    "    cols = pd.MultiIndex.from_product([[ticker], ['open', 'high', 'low', 'close', 'volume', 'vwap', 'transactions']])\n",
    "    \n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    time_stamps = []\n",
    "    while start_date < end_date:\n",
    "        try:\n",
    "            current_period = start_date.strftime(\"%Y-%m-%d\")\n",
    "            next_period = (start_date + timedelta(days=1000)).strftime(\"%Y-%m-%d\")\n",
    "            for a in client.list_aggs(\n",
    "                ticker,\n",
    "                15,\n",
    "                \"minute\",\n",
    "                current_period,\n",
    "                next_period,\n",
    "                limit=50000,\n",
    "            ):\n",
    "                time_stamps.append(a.timestamp)\n",
    "                data = {\n",
    "                    (ticker,'open'): [a.open],\n",
    "                    (ticker,'high'): [a.high], \n",
    "                    (ticker,'low'): [a.low],\n",
    "                    (ticker,'close'): [a.close],\n",
    "                    (ticker,'volume'): [a.volume],\n",
    "                    (ticker,'vwap'): [a.vwap],\n",
    "                    (ticker,'transactions'): [a.transactions]\n",
    "                }\n",
    "                new_row = pd.DataFrame(columns=cols, data=data)\n",
    "                df = pd.concat([df, new_row], ignore_index=True)\n",
    "        except:\n",
    "            print(\"{\" + ticker + \"}\" + \" No Data for \" + current_period + \" to \" + next_period + \".\")\n",
    "        start_date = start_date + timedelta(days=1001)\n",
    "\n",
    "    # Set the timezone to UTC\n",
    "    utc_time = pd.to_datetime(time_stamps, unit='ms', utc=True)\n",
    "    # Convert to Eastern Time\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    eastern_time = utc_time.tz_convert(eastern)\n",
    "    df.index = eastern_time\n",
    "\n",
    "    return df #pd.Series(close_prices, index=pd.to_datetime(time_stamps, unit='s'), name=ticker\n",
    "\n",
    "# Define your API key here\n",
    "api_key = 'FuGEoCgmKhdpXJVy7pNqWD_TlARMHuMa'\n",
    "\n",
    "# Initialize the RESTClient with the API key\n",
    "client = RESTClient(api_key)\n",
    "\n",
    "# Replace with the path to your CSV file containing tickers\n",
    "tickers_csv_path = \"tickers.csv\"\n",
    "ticker_list = read_csv_to_list(tickers_csv_path)\n",
    "# ticker_list = ['AADI']\n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through tickers and retrieve data\n",
    "start_date = datetime(2015, 1, 1)\n",
    "end_date = datetime(2023, 10, 1)\n",
    "for ticker in ticker_list:\n",
    "    df = get_data(client, ticker, start_date, end_date)\n",
    "    if not df.empty:\n",
    "        combined_df = pd.concat([combined_df, df], axis=1)\n",
    "\n",
    "# Sort the DataFrame by its datetime index\n",
    "combined_df.sort_index(inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "#combined_df.to_csv(\"stock_data.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
